{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The points distribution for this case is as follows:\n",
    "1. Read the dataset\n",
    "2. Drop the columns which are unique for all users like IDs (2.5 points)\n",
    "3. Distinguish the feature and target set (2.5 points)\n",
    "4. Divide the data set into Train and test sets\n",
    "5. Normalize the train and test data (2.5 points)\n",
    "6. Initialize &amp; build the model (10 points)\n",
    "7. Optimize the model (5 points)\n",
    "9. Predict the results using 0.5 as a threshold (5 points)\n",
    "10. Print the Accuracy score and confusion matrix (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------1--------------------------------------------------\n",
    "# Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('bank.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check columns list and missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------2--------------------------------------------------\n",
    "# Drop the columns which are unique for all users like IDs (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          10000\n",
       "CustomerId         10000\n",
       "Surname             2932\n",
       "CreditScore          460\n",
       "Geography              3\n",
       "Gender                 2\n",
       "Age                   70\n",
       "Tenure                11\n",
       "Balance             6382\n",
       "NumOfProducts          4\n",
       "HasCrCard              2\n",
       "IsActiveMember         2\n",
       "EstimatedSalary     9999\n",
       "Exited                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns as explained above\n",
    "df = df.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the top rows of what is left of the data frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check variable data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------3--------------------------------------------------\n",
    "# Distinguish the feature and target set (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Feature Sets are entire dataset excluding Exited\n",
    "# The Target Set is Exited column\n",
    "X= df.iloc[:,0:10]\n",
    "y= df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y=df[['Exited']]\n",
    "#X= df.drop('Exited', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619          0  Female   42       2       0.00              1   \n",
       "1          608          2  Female   41       1   83807.86              1   \n",
       "2          502          0  Female   42       8  159660.80              3   \n",
       "3          699          0  Female   39       1       0.00              2   \n",
       "4          850          2  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#deal with categorical data --> encode them\n",
    "\n",
    "labelencoder_x = LabelEncoder()\n",
    "X.iloc[:, 1] = labelencoder_x.fit_transform(X.iloc[:, 1]) #applying on Geography\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619          0       0   42       2       0.00              1   \n",
       "1          608          2       0   41       1   83807.86              1   \n",
       "2          502          0       0   42       8  159660.80              3   \n",
       "3          699          0       0   39       1       0.00              2   \n",
       "4          850          2       0   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply encoder on Gender as well\n",
    "labelencoder_x_2 = LabelEncoder()\n",
    "X.iloc[:, 2] = labelencoder_x_2.fit_transform(X.iloc[:, 2]) #applying on Gender\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#One hot encoding. \n",
    "\n",
    "from keras.utils import to_categorical\n",
    "encoded = pd.DataFrame(to_categorical(X.iloc[:, 1]))\n",
    "#no need to encode Gender, as there are only two categories\n",
    "\n",
    "X = pd.concat([encoded, X], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------4--------------------------------------------------\n",
    "# Divide the data set into Train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 10)\n",
      "(2000, 10)\n",
      "(8000,)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------5--------------------------------------------------\n",
    "# Normalize the train and test data (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------6--------------------------------------------------\n",
    "# Initialize &amp; build the model (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  tf.keras.models.Sequential()\n",
    "#seed=50\n",
    "#np.random.seed(seed)\n",
    "model.add(tf.keras.layers.Dense(input_dim=10, activation='relu',units=6,kernel_initializer='uniform',name='fc1'))\n",
    "model.add(tf.keras.layers.Dense(kernel_initializer='uniform',units=6, activation='relu',name='fc2'))\n",
    "model.add(tf.keras.layers.Dense(activation = 'sigmoid', units=1, kernel_initializer='uniform',name='output')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1 (Dense)                  (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 115\n",
      "Trainable params: 115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 4s 462us/step - loss: 0.5601 - acc: 0.7960 - val_loss: 0.4445 - val_acc: 0.7975\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4405 - acc: 0.7960 - val_loss: 0.4355 - val_acc: 0.7975\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4356 - acc: 0.7960 - val_loss: 0.4315 - val_acc: 0.7975\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.4328 - acc: 0.7960 - val_loss: 0.4309 - val_acc: 0.7975\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4308 - acc: 0.7960 - val_loss: 0.4272 - val_acc: 0.7975\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.4280 - acc: 0.7960 - val_loss: 0.4233 - val_acc: 0.7975\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.4252 - acc: 0.8001 - val_loss: 0.4219 - val_acc: 0.8195\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.4230 - acc: 0.8176 - val_loss: 0.4191 - val_acc: 0.8205\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.4220 - acc: 0.8196 - val_loss: 0.4180 - val_acc: 0.8230\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.4204 - acc: 0.8229 - val_loss: 0.4170 - val_acc: 0.8255\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.4191 - acc: 0.8244 - val_loss: 0.4162 - val_acc: 0.8310\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.4181 - acc: 0.8272 - val_loss: 0.4149 - val_acc: 0.8300\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 0.4171 - acc: 0.8276 - val_loss: 0.4137 - val_acc: 0.8305\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.4160 - acc: 0.8281 - val_loss: 0.4128 - val_acc: 0.8295\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.4152 - acc: 0.8286 - val_loss: 0.4127 - val_acc: 0.8350\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.4142 - acc: 0.8314 - val_loss: 0.4111 - val_acc: 0.8360\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.4131 - acc: 0.8317 - val_loss: 0.4102 - val_acc: 0.8395\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.4120 - acc: 0.8322 - val_loss: 0.4085 - val_acc: 0.8365\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.4115 - acc: 0.8325 - val_loss: 0.4095 - val_acc: 0.8395\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.4105 - acc: 0.8324 - val_loss: 0.4080 - val_acc: 0.8385\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.4095 - acc: 0.8336 - val_loss: 0.4077 - val_acc: 0.8390\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.4088 - acc: 0.8331 - val_loss: 0.4079 - val_acc: 0.8385\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.4083 - acc: 0.8337 - val_loss: 0.4067 - val_acc: 0.8400\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.4077 - acc: 0.8332 - val_loss: 0.4044 - val_acc: 0.8410\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.4071 - acc: 0.8350 - val_loss: 0.4070 - val_acc: 0.8395\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.4068 - acc: 0.8354 - val_loss: 0.4052 - val_acc: 0.8400\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.4066 - acc: 0.8348 - val_loss: 0.4038 - val_acc: 0.8395\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.4059 - acc: 0.8349 - val_loss: 0.4042 - val_acc: 0.8395\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.4058 - acc: 0.8346 - val_loss: 0.4041 - val_acc: 0.8400\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.4052 - acc: 0.8337 - val_loss: 0.4041 - val_acc: 0.8385\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.4048 - acc: 0.8357 - val_loss: 0.4038 - val_acc: 0.8400\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.4048 - acc: 0.8340 - val_loss: 0.4057 - val_acc: 0.8415\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.4043 - acc: 0.8345 - val_loss: 0.4035 - val_acc: 0.8410\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4042 - acc: 0.8344 - val_loss: 0.4034 - val_acc: 0.8405\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.4041 - acc: 0.8353 - val_loss: 0.4017 - val_acc: 0.8410\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 95us/step - loss: 0.4035 - acc: 0.8356 - val_loss: 0.4029 - val_acc: 0.8410\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.4035 - acc: 0.8350 - val_loss: 0.4014 - val_acc: 0.8400\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.4033 - acc: 0.8355 - val_loss: 0.4023 - val_acc: 0.8420\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.4030 - acc: 0.8346 - val_loss: 0.4014 - val_acc: 0.8410\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.4028 - acc: 0.8357 - val_loss: 0.4028 - val_acc: 0.8400\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.4028 - acc: 0.8359 - val_loss: 0.4008 - val_acc: 0.8415\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.4024 - acc: 0.8359 - val_loss: 0.4006 - val_acc: 0.8410\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.4024 - acc: 0.8348 - val_loss: 0.4014 - val_acc: 0.8410\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.4021 - acc: 0.8359 - val_loss: 0.3998 - val_acc: 0.8410\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.4019 - acc: 0.8353 - val_loss: 0.3997 - val_acc: 0.8400\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.4020 - acc: 0.8357 - val_loss: 0.4002 - val_acc: 0.8410\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 0s 60us/step - loss: 0.4019 - acc: 0.8357 - val_loss: 0.4004 - val_acc: 0.8430\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.4016 - acc: 0.8357 - val_loss: 0.4000 - val_acc: 0.8425\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.4016 - acc: 0.8349 - val_loss: 0.4002 - val_acc: 0.8410\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.4016 - acc: 0.8348 - val_loss: 0.4006 - val_acc: 0.8415\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.4010 - acc: 0.8356 - val_loss: 0.4003 - val_acc: 0.8390\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.4008 - acc: 0.8355 - val_loss: 0.3994 - val_acc: 0.8400\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 57us/step - loss: 0.4009 - acc: 0.8361 - val_loss: 0.3992 - val_acc: 0.8430\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.4007 - acc: 0.8354 - val_loss: 0.3993 - val_acc: 0.8430\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 0s 52us/step - loss: 0.4003 - acc: 0.8364 - val_loss: 0.3990 - val_acc: 0.8395\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s 53us/step - loss: 0.4009 - acc: 0.8367 - val_loss: 0.3986 - val_acc: 0.8415\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.4004 - acc: 0.8371 - val_loss: 0.3995 - val_acc: 0.8430\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 0s 56us/step - loss: 0.4005 - acc: 0.8380 - val_loss: 0.3997 - val_acc: 0.8410\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 0s 55us/step - loss: 0.4002 - acc: 0.8371 - val_loss: 0.3981 - val_acc: 0.8405\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.4000 - acc: 0.8364 - val_loss: 0.3994 - val_acc: 0.8370\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3996 - acc: 0.8359 - val_loss: 0.3992 - val_acc: 0.8385\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.3999 - acc: 0.8384 - val_loss: 0.3995 - val_acc: 0.8400\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3996 - acc: 0.8370 - val_loss: 0.4006 - val_acc: 0.8385\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3996 - acc: 0.8364 - val_loss: 0.3994 - val_acc: 0.8395\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3996 - acc: 0.8357 - val_loss: 0.3995 - val_acc: 0.8395\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3997 - acc: 0.8365 - val_loss: 0.3988 - val_acc: 0.8425\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3991 - acc: 0.8371 - val_loss: 0.3977 - val_acc: 0.8395\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3998 - acc: 0.8369 - val_loss: 0.3977 - val_acc: 0.8430\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3996 - acc: 0.8354 - val_loss: 0.3975 - val_acc: 0.8425\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3991 - acc: 0.8353 - val_loss: 0.3982 - val_acc: 0.8400\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3995 - acc: 0.8374 - val_loss: 0.3989 - val_acc: 0.8410\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3993 - acc: 0.8354 - val_loss: 0.3992 - val_acc: 0.8415\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3991 - acc: 0.8374 - val_loss: 0.3967 - val_acc: 0.8410\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3994 - acc: 0.8360 - val_loss: 0.3973 - val_acc: 0.8415\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.3995 - acc: 0.8360 - val_loss: 0.3975 - val_acc: 0.8420\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 86us/step - loss: 0.3990 - acc: 0.8365 - val_loss: 0.3979 - val_acc: 0.8435\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3990 - acc: 0.8363 - val_loss: 0.3985 - val_acc: 0.8415\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3987 - acc: 0.8365 - val_loss: 0.3969 - val_acc: 0.8430\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3992 - acc: 0.8355 - val_loss: 0.3977 - val_acc: 0.8410\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3991 - acc: 0.8354 - val_loss: 0.3969 - val_acc: 0.8420\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3990 - acc: 0.8350 - val_loss: 0.3975 - val_acc: 0.8425\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3988 - acc: 0.8351 - val_loss: 0.3974 - val_acc: 0.8405\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3991 - acc: 0.8353 - val_loss: 0.3982 - val_acc: 0.8430\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3987 - acc: 0.8359 - val_loss: 0.3979 - val_acc: 0.8435\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3988 - acc: 0.8354 - val_loss: 0.3985 - val_acc: 0.8420\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3989 - acc: 0.8360 - val_loss: 0.3979 - val_acc: 0.8415\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3989 - acc: 0.8355 - val_loss: 0.3978 - val_acc: 0.8425\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3988 - acc: 0.8357 - val_loss: 0.3988 - val_acc: 0.8410\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3987 - acc: 0.8351 - val_loss: 0.3976 - val_acc: 0.8410\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 0s 58us/step - loss: 0.3988 - acc: 0.8354 - val_loss: 0.3974 - val_acc: 0.8405\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3989 - acc: 0.8350 - val_loss: 0.3981 - val_acc: 0.8415\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3989 - acc: 0.8354 - val_loss: 0.3971 - val_acc: 0.8390\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.3986 - acc: 0.8364 - val_loss: 0.3975 - val_acc: 0.8400\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3986 - acc: 0.8346 - val_loss: 0.3972 - val_acc: 0.8420\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3986 - acc: 0.8359 - val_loss: 0.3971 - val_acc: 0.8400\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3985 - acc: 0.8355 - val_loss: 0.3970 - val_acc: 0.8435\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.3987 - acc: 0.8351 - val_loss: 0.3985 - val_acc: 0.8430\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3985 - acc: 0.8357 - val_loss: 0.3969 - val_acc: 0.8430\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3984 - acc: 0.8345 - val_loss: 0.3969 - val_acc: 0.8415\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 0s 59us/step - loss: 0.3985 - acc: 0.8341 - val_loss: 0.3975 - val_acc: 0.8415\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b0ad167f60>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------7--------------------------------------------------\n",
    "# Optimize the model (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 =  tf.keras.models.Sequential()\n",
    "seed=50\n",
    "np.random.seed(seed)\n",
    "model1.add(tf.keras.layers.Dense(input_dim=10, activation='relu',units=6,kernel_initializer='uniform',name='fc1'))\n",
    "model1.add(tf.keras.layers.BatchNormalization())\n",
    "model1.add(tf.keras.layers.Dense(kernel_initializer='uniform',units=6, activation='relu',name='fc2'))\n",
    "model1.add(tf.keras.layers.Dense(activation = 'sigmoid', units=1, kernel_initializer='uniform',name='output')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1 (Dense)                  (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 139\n",
      "Trainable params: 127\n",
      "Non-trainable params: 12\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
    "model1.compile(loss='binary_crossentropy',optimizer=sgd_optimizer,metrics=['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 2s 193us/step - loss: 0.5612 - acc: 0.7935 - val_loss: 0.5127 - val_acc: 0.7975\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.5087 - acc: 0.7960 - val_loss: 0.5043 - val_acc: 0.7975\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.5050 - acc: 0.7960 - val_loss: 0.5009 - val_acc: 0.7975\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.4965 - acc: 0.7960 - val_loss: 0.4744 - val_acc: 0.7975\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.4591 - acc: 0.8034 - val_loss: 0.4250 - val_acc: 0.8245\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.4287 - acc: 0.8174 - val_loss: 0.3908 - val_acc: 0.8490\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.3968 - acc: 0.8329 - val_loss: 0.3762 - val_acc: 0.8465\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.3831 - acc: 0.8392 - val_loss: 0.3625 - val_acc: 0.8500\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3761 - acc: 0.8421 - val_loss: 0.3555 - val_acc: 0.8560\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3715 - acc: 0.8438 - val_loss: 0.3606 - val_acc: 0.8515\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3717 - acc: 0.8452 - val_loss: 0.3552 - val_acc: 0.8570\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3685 - acc: 0.8476 - val_loss: 0.3528 - val_acc: 0.8605\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3648 - acc: 0.8444 - val_loss: 0.3577 - val_acc: 0.8615\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3652 - acc: 0.8499 - val_loss: 0.3493 - val_acc: 0.8620\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3614 - acc: 0.8531 - val_loss: 0.3532 - val_acc: 0.8550\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3634 - acc: 0.8480 - val_loss: 0.3504 - val_acc: 0.8580\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3596 - acc: 0.8522 - val_loss: 0.3454 - val_acc: 0.8595\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.3595 - acc: 0.8545 - val_loss: 0.3492 - val_acc: 0.8595\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3592 - acc: 0.8541 - val_loss: 0.3516 - val_acc: 0.8585\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3561 - acc: 0.8508 - val_loss: 0.3476 - val_acc: 0.8600\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3556 - acc: 0.8534 - val_loss: 0.3448 - val_acc: 0.8640\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3551 - acc: 0.8551 - val_loss: 0.3503 - val_acc: 0.8555\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.3570 - acc: 0.8546 - val_loss: 0.3507 - val_acc: 0.8540\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3553 - acc: 0.8561 - val_loss: 0.3416 - val_acc: 0.8605\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3526 - acc: 0.8551 - val_loss: 0.3527 - val_acc: 0.8565\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3560 - acc: 0.8514 - val_loss: 0.3446 - val_acc: 0.8595\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3543 - acc: 0.8558 - val_loss: 0.3416 - val_acc: 0.8615\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3544 - acc: 0.8535 - val_loss: 0.3416 - val_acc: 0.8620\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.3538 - acc: 0.8559 - val_loss: 0.3420 - val_acc: 0.8615\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3511 - acc: 0.8576 - val_loss: 0.3414 - val_acc: 0.8560\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 1s 88us/step - loss: 0.3472 - acc: 0.8565 - val_loss: 0.3415 - val_acc: 0.8625\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3496 - acc: 0.8554 - val_loss: 0.3385 - val_acc: 0.8610\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3495 - acc: 0.8556 - val_loss: 0.3390 - val_acc: 0.8615\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3476 - acc: 0.8556 - val_loss: 0.3442 - val_acc: 0.8585\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3503 - acc: 0.8561 - val_loss: 0.3368 - val_acc: 0.8565\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3480 - acc: 0.8595 - val_loss: 0.3439 - val_acc: 0.8605\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3462 - acc: 0.8596 - val_loss: 0.3348 - val_acc: 0.8630\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3492 - acc: 0.8581 - val_loss: 0.3366 - val_acc: 0.8625\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3485 - acc: 0.8559 - val_loss: 0.3378 - val_acc: 0.8635\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3450 - acc: 0.8591 - val_loss: 0.3364 - val_acc: 0.8640\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - ETA: 0s - loss: 0.3471 - acc: 0.856 - 1s 68us/step - loss: 0.3480 - acc: 0.8564 - val_loss: 0.3345 - val_acc: 0.8615\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3470 - acc: 0.8562 - val_loss: 0.3377 - val_acc: 0.8590\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3461 - acc: 0.8601 - val_loss: 0.3364 - val_acc: 0.8625\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3481 - acc: 0.8545 - val_loss: 0.3331 - val_acc: 0.8645\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3479 - acc: 0.8594 - val_loss: 0.3348 - val_acc: 0.8620\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 1s 94us/step - loss: 0.3459 - acc: 0.8568 - val_loss: 0.3325 - val_acc: 0.8605\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3449 - acc: 0.8598 - val_loss: 0.3346 - val_acc: 0.8625\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3458 - acc: 0.8582 - val_loss: 0.3363 - val_acc: 0.8635\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3463 - acc: 0.8576 - val_loss: 0.3331 - val_acc: 0.8620\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3451 - acc: 0.8600 - val_loss: 0.3351 - val_acc: 0.8605\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3471 - acc: 0.8578 - val_loss: 0.3328 - val_acc: 0.8615\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3467 - acc: 0.8585 - val_loss: 0.3323 - val_acc: 0.8650\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3455 - acc: 0.8605 - val_loss: 0.3341 - val_acc: 0.8635\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 0s 61us/step - loss: 0.3446 - acc: 0.8589 - val_loss: 0.3334 - val_acc: 0.8645\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3452 - acc: 0.8590 - val_loss: 0.3301 - val_acc: 0.8620\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 0s 62us/step - loss: 0.3451 - acc: 0.8575 - val_loss: 0.3335 - val_acc: 0.8610\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3440 - acc: 0.8608 - val_loss: 0.3329 - val_acc: 0.8645\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3441 - acc: 0.8590 - val_loss: 0.3338 - val_acc: 0.8600\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.3440 - acc: 0.8591 - val_loss: 0.3308 - val_acc: 0.8680\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 1s 80us/step - loss: 0.3460 - acc: 0.8594 - val_loss: 0.3312 - val_acc: 0.8650\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3427 - acc: 0.8592 - val_loss: 0.3344 - val_acc: 0.8630\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3464 - acc: 0.8580 - val_loss: 0.3322 - val_acc: 0.8640\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3413 - acc: 0.8609 - val_loss: 0.3350 - val_acc: 0.8570\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3416 - acc: 0.8613 - val_loss: 0.3318 - val_acc: 0.8660\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3441 - acc: 0.8599 - val_loss: 0.3348 - val_acc: 0.8590\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3437 - acc: 0.8585 - val_loss: 0.3320 - val_acc: 0.8590\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3440 - acc: 0.8599 - val_loss: 0.3289 - val_acc: 0.8670\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3449 - acc: 0.8590 - val_loss: 0.3295 - val_acc: 0.8685\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3449 - acc: 0.8560 - val_loss: 0.3308 - val_acc: 0.8635\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 1s 77us/step - loss: 0.3457 - acc: 0.8586 - val_loss: 0.3306 - val_acc: 0.8675\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 1s 73us/step - loss: 0.3425 - acc: 0.8581 - val_loss: 0.3340 - val_acc: 0.8665\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3439 - acc: 0.8596 - val_loss: 0.3326 - val_acc: 0.8605\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3418 - acc: 0.8618 - val_loss: 0.3298 - val_acc: 0.8655\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 1s 81us/step - loss: 0.3435 - acc: 0.8594 - val_loss: 0.3311 - val_acc: 0.8635\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3446 - acc: 0.8594 - val_loss: 0.3313 - val_acc: 0.8630\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 1s 75us/step - loss: 0.3416 - acc: 0.8603 - val_loss: 0.3316 - val_acc: 0.8640\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3420 - acc: 0.8590 - val_loss: 0.3289 - val_acc: 0.8680\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3435 - acc: 0.8596 - val_loss: 0.3290 - val_acc: 0.8660\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3424 - acc: 0.8589 - val_loss: 0.3313 - val_acc: 0.8640\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 1s 66us/step - loss: 0.3439 - acc: 0.8572 - val_loss: 0.3316 - val_acc: 0.8650\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3437 - acc: 0.8605 - val_loss: 0.3316 - val_acc: 0.8675\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 1s 70us/step - loss: 0.3427 - acc: 0.8598 - val_loss: 0.3321 - val_acc: 0.8660\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 1s 71us/step - loss: 0.3438 - acc: 0.8591 - val_loss: 0.3337 - val_acc: 0.8645\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.3421 - acc: 0.8571 - val_loss: 0.3321 - val_acc: 0.8665\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 1s 74us/step - loss: 0.3422 - acc: 0.8616 - val_loss: 0.3333 - val_acc: 0.8655\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 1s 92us/step - loss: 0.3424 - acc: 0.8615 - val_loss: 0.3309 - val_acc: 0.8680\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 1s 83us/step - loss: 0.3436 - acc: 0.8590 - val_loss: 0.3297 - val_acc: 0.8650\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 1s 79us/step - loss: 0.3442 - acc: 0.8571 - val_loss: 0.3304 - val_acc: 0.8650\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3437 - acc: 0.8595 - val_loss: 0.3322 - val_acc: 0.8640\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 1s 76us/step - loss: 0.3424 - acc: 0.8598 - val_loss: 0.3281 - val_acc: 0.8675\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 1s 72us/step - loss: 0.3418 - acc: 0.8609 - val_loss: 0.3319 - val_acc: 0.8610\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 1s 82us/step - loss: 0.3413 - acc: 0.8594 - val_loss: 0.3313 - val_acc: 0.8605\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 1s 68us/step - loss: 0.3430 - acc: 0.8585 - val_loss: 0.3354 - val_acc: 0.8575\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 1s 65us/step - loss: 0.3408 - acc: 0.8600 - val_loss: 0.3306 - val_acc: 0.8675\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 1s 69us/step - loss: 0.3413 - acc: 0.8571 - val_loss: 0.3309 - val_acc: 0.8605\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 1s 63us/step - loss: 0.3403 - acc: 0.8609 - val_loss: 0.3318 - val_acc: 0.8655\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 1s 67us/step - loss: 0.3420 - acc: 0.8595 - val_loss: 0.3324 - val_acc: 0.8665\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 1s 64us/step - loss: 0.3420 - acc: 0.8594 - val_loss: 0.3278 - val_acc: 0.8665\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.3433 - acc: 0.8571 - val_loss: 0.3302 - val_acc: 0.8635\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 1s 84us/step - loss: 0.3433 - acc: 0.8601 - val_loss: 0.3305 - val_acc: 0.8635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b0ad9b89e8>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train,validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------9--------------------------------------------------\n",
    "# Predict the results using 0.5 as a threshold (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]\n",
      " [False]\n",
      " [False]\n",
      " ...\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n"
     ]
    }
   ],
   "source": [
    "predict=model1.predict(X_test)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]\n",
      " [False]\n",
      " [False]\n",
      " ...\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n"
     ]
    }
   ],
   "source": [
    "predict=predict>0.5\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------10--------------------------------------------------\n",
    "# Print the Accuracy score and confusion matrix (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1519   76]\n",
      " [ 197  208]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, predict)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 22us/step\n"
     ]
    }
   ],
   "source": [
    "results = model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test set loss: 0.330503\n",
      "Final test set accuracy: 0.863500\n"
     ]
    }
   ],
   "source": [
    "print('Final test set loss: {:4f}'.format(results[0]))\n",
    "print('Final test set accuracy: {:4f}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86.35 % of testing data was classified correctly\n"
     ]
    }
   ],
   "source": [
    "print (((cm[0][0]+cm[1][1])*100)/(cm[0][0]+cm[1][1]+cm[0][1]+cm[1][0]), '% of testing data was classified correctly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
